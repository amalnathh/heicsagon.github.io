<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" keywords="seo, search engines">
    <title>Intro to Search Engine Optimization</title>
    <style>
        html,
        * {
            font-family: Arial, Helvetica, sans-serif;
            margin: 0;
            padding: 0;
        }

        header {
            height: 50px;
            background-color: rgb(172, 182, 182);
        }

        p {
            margin: 2px;
            padding: 10px;
        }

        h1 {
            padding: 13px;
        }

        .container {
            display: flex;
            justify-content: center;
        }

        .container>div {
            width: 70%;
        }

        @media screen and (max-width:600px) {
            .container>div {
                width: 90%;
            }
        }
    </style>
</head>

<body>
    <header>
        <div class="div_container">
            <div class="heixa">
                <h1>he<span style="color:green;">i</span>csagon</h1>
            </div>
        </div>
    </header>
    <div class="container">
        <div>
            <h1>Introduction to search engine optimisation</h1>
            <b>Summary:</b><br>
            <p>Search engines are one of the primary ways that Internet users find websites. That&rsquo;s why a web site
                with
                good search engine listings may see a dramatic increase in traffic.</p>
            <p><br></p>
            <h2>Human-Powered Directories </h2>
            <p>A human-powered directory, such as the Open Directory, depends on humans for its listings. You submit a
                short
                description to the directory for your entire site, or editors write one for sites they review. A search
                looks for
                matches only in the description submitted.</p>
            <p><br></p>
            <p>Changing your web pages has no effect on your listing. Things that are useful for improving a listing
                with a
                search engine have nothing to do with improving a listing in a directory. The only exception is that a
                good
                site, with
                good content, might be more likely to get reviewed for free than a poor site.</p>
            <p><br></p>
            <h2>Crawler-Based Search Engines </h2>
            <p>Crawler-Based search engines, such as Google, create their listings automatically. They
                &ldquo;crawl&rdquo;
                or
                &ldquo;spider&rdquo; the web, then people search through what they have found.
                If you change your web pages, crawler-based search engines eventually find these changes, and that can
                affect how
                you are listed. Page titles, body copy and other elements all play a role.</p>
            <p><br></p>
            <h3>The Parts of a Crawler-Based Search Engine </h3>
            <p>Crawler-based search engines have three major elements. First is the spider, also call the crawler. The
                spider
                visits a web page, reads it, and then follows links to other pages within the site. This is what it
                means
                when someone
                refers to a site being &ldquo;spidered&rdquo; or &ldquo;crawled&rdquo;. The spider returns to the site
                on a
                regular basis,
                such as every month or two, to look for changes.</p>
            <p>Everything the spider finds goes into the second part of the search engine, the index. The index,
                sometimes
                called the catalog, is like a giant book containing a copy of every web page that the spider finds. If a
                web
                page changes,
                then this book is updated with new information.Sometimes it can take a while for new pages or changes
                that
                the spider finds to be added to the index. Thus a web
                page may have been &ldquo;spidered&rdquo; but not yet &ldquo;indexed&rdquo;. Until it is indexed &ndash;
                added to the
                index &ndash; it is not available to those searching with the search engine.</p>
            <p>Search engine software is the third part of a search engine. This is the program that sifts through the
                millions
                of pages recorded in the index to find matches to a search and rank them in order of what it believes is
                most
                relevant.</p>
            <h2>Major Search Engines: The same, but different </h2>
            <p>All crawler-based search engines have the basic parts described above, but there are differences in how
                these
                parts are tuned. That is why the same search on different search engines often produces different
                results.
            </p>
            <p>Now lets look more about how crawler-based search engine rank the listings that they gather.</p>
            <p><br></p>
            <h2>How Search Engines Rank Web Pages </h2>
            <p>Search for anything using your favorite crawler-based search engine. Nearly instantly, the search engine
                will
                sort through the millions of pages it knows about and present you with ones that much your topic. The
                matches will
                even be ranked, so that the most relevant ones come first. <br> Of course, the search engines
                don&rsquo;t
                always get it right. Non-relevant pages make it through, and sometimes
                it may take a little more digging to find what you are looking for. But, by and large, search engines do
                an
                amazing job.</p>

            <p>As WebCrawler founder Brian Pinkerton puts it, &ldquo;Imagine walking up to a librarian and saying&rdquo;
                &lsquo;travel&rsquo;. They are going to look at you with a blank face&rdquo;.</p>

            <p>Ok- a librarian&rsquo;s not really going to stare at you with a vacant expression. Instead, they are
                going to
                ask
                you question</p>
            <p>to better understand what you are looking for.</p>

            <p>Unfortunately, search engines don&rsquo;t have the ability to ask a few questions to focus search, as
                librarians
                can. They also can&rsquo;t rely on judgment and past experience to rank web pages, in the way humans
                can.
            </p>

            <p>So, how do crawler-based search engines go about determining relevancy, when confronted with hundreds of
                millions
                of web pages to sort through? They follow a set of rules, known as an algorithm. Exactly how a
                particular
                search
                engine&rsquo;s algorithm works is a closely kept trade secret. However, all major search engines follow
                the
                general rules below.
            </p>
            <p>Location, Location, Location&hellip; and Frequency</p>
            <p>One of the main rules in a ranking algorithm involves the location and frequency of keywords on a web
                page.
                Call
                it the location/frequency method, for short.</p>
            <p>Remember the librarian mentioned above? They need to find books to match your request of
                &ldquo;travel&rdquo;, so
                it makes sense that they first look at books with travel in the title. Search engines operate the same
                way.
                Pages with the
                search terms appearing in the HTML title tag are often assumed to be more relevant than others to the
                topic.
            </p>
            <p>Search engines will also check to see if the search keywords appear near the top of a web page, such as
                in
                the
                headline or in the first few paragraphs of text. They assume that any page \relevant tot the topic will
                mention those
                words right from the beginning.</p>
            <p><br></p>
            <p>Frequency is the other major factor in how search engines determine relevancy. A search engine will
                analyze
                how
                often keywords appear in relation other words in a web page. Those with a higher frequency are often
                deemed
                more
                relevant than other web pages.</p>
            <p><br></p>
            <h3>Spice in the Recipe </h3>
            <p>Now it&rsquo;s time to qualify the location/frequency method described above. All the major search
                engines
                follow
                it to some degree; in the same way cooks may follow a standard chili recipe. But cooks like to add their
                own
                secret
                ingredients. In the same way, search engines and spice to the location/frequency method. Nobody does it
                exactly the same, which
                is one reason why the same search on different search engines produces different result.</p>
            <p><br></p>
            <p>To begin with, some search engines index more web pages than others. Some search engines also index web
                pages
                more often than others. The result is that no search engine has the exact same collection of web pages
                to
                search through.
                That naturally produces differences, when comparing their results.</p>
            <br>
            <p>Search engines may also penalize pages or exclude them from the index, if they detect search engine
                &ldquo;spamming&rdquo;. An example is when a word is repeated hundreds of time on a page, to increase
                the
                frequency and propel the page
                higher in the listings. Search engines watch for common spamming methods in a variety of ways, including
                following up on
                complaints from their users.</p>
            <p><br></p>
            <h3>Off the page factors </h3>
            <p>Crawler-based search engines have plenty of experience now with webmasters who constantly rewrite their
                web
                pages
                in an attempt to gain better rankings. Some sophisticated webmasters may even go to great lengths to
                &ldquo;reverse
                engineer&rdquo; the location/frequency systems used by a particular search engine. Because of this, all
                major search engines now also
                make use of &ldquo;off the page&rdquo; ranking criteria.</p>
            <br>
            <p>Off the page factors are those that a webmasters cannot easily influence. Chief among these is link
                analysis.
                By
                analyzing how pages link to each other, a search engine can both determine what a page is about and
                whether
                that
                page is deemed to be &ldquo;important&rdquo; and thus deserving of a ranking boost. In addition,
                sophisticated techniques
                are used to screen out attempts by webmasters to build &ldquo;artificial&rdquo; links designed to boost
                their rankings.</p>
            <br>
            <p>Another off the page factor is click through measurement. In short, this means that a search engine may
                watch
                what result someone selects for a particular search, then eventually drop high-ranking pages that
                aren&rsquo;t
                attracting clicks, >while promoting lower-ranking pages that do pull in visitors. As with link analysis,
                systems are used to
                compensate for artificial links generated by eager webmasters.</p>
            <p><br></p>
            <h3>Search Engine Ranking Tips </h3>
            <p>A query on a crawler-based search engine often turns up thousands or even millions of matching web pages.
                In
                many
                cases,>only the 10 most &ldquo;relevant&rdquo; matches are displayed on the first page.</p>
            <p>Naturally, anyone who runs a website wants to be in the &ldquo;top ten&rdquo; results. This is because
                most
                users
                will find a result they like in the top ten. Being listed 11 or beyond means that many people may miss
                your
                web site. The tips below will help you come closer to this goal, both for the keywords you think are
                important and for
                phrases you may not even be anticipating.</p>
            <p>For example, say you have a page devoted to stamp collecting. Anytime someone types, &ldquo;stamp
                collecting&rdquo;, you want your page to be in the top ten results. Then those are your target keywords
                for
                that page.</p>

            <p>Each page in you web site will have different target keywords that reflect the page&rsquo;s content. For
                example,
                say you have another page about the history of stamps. Then &ldquo;stamp history&rdquo; might be your
                keywords for that page.
                <br> Your target keywords should always be at least two or more words long. Usually, too many sites will
                be
                relevant
                for a single word, such as &ldquo;stamps&rdquo;. This competition means your odds of success are lower.
                Don&rsquo;t
                waste your time fighting the odds. Pick phrases of two or more words, and you will have a better shot at
                success.</p>

        </div>
    </div>
</body>

</html>